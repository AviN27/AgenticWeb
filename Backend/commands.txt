- ghvenv\Scripts\activate
- set KAFKA_BOOTSTRAP=localhost:9092
- set REDIS_URL=redis://localhost:6379

- docker compose ps -q redpanda
- docker exec -it {redpanda-image-id} rpk topic list
- docker exec -it {redpanda-image-id} rpk topic create inbox transcript agent.cmd agent.out.ride agent.out.food agent.out.mart agent.error agent.status agent.out.clarify
    - Topic List:
        - inbox
        - transcript
        - agent.cmd
        - agent.out.ride
        - agent.out.food
        - agent.out.mart
        - agent.error
        - agent.status
        - agent.out.clarify
        
- py -m venv ghvenv
- docker compose exec redis redis-cli
- JSON.GET user:demo-user

- uvicorn services.context.static:app --host 0.0.0.0 --port 8001
- uvicorn services.context.semantic:app --host 0.0.0.0 --port 8002
- uvicorn services.adapters.main:app --host 0.0.0.0 --port 8100

JSON.SET clarify:7c885e54-4eb8-4311-a88c-a7af40a65961 '$' '"1 Zinger Burger and 1 medium fries"'

// FINE TUNE CLARIFY FLOW. MAKE STATIC DATA AND SEMANTIC DATA AS CONTEXT TO CLARIFY FLOW.
// LLM SHOULD IDENTIFY WHEN TO USE STATIC FAVOURITES, SEMANTIC TIMESERIES DATA AND WHEN TO PROMPT BACK THE USER. 

// CURRENTLY USER PROMPT BACK IS WORKING, SOME CONTEXT IS MISSING SO DATA IS GETTING OVERRIDED.